{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency loaded!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import keras\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from scipy.misc.pilutil import imresize\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "# For deep learning functions with keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, MaxPooling2D, Activation, Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import  Adam\n",
    "\n",
    "print (\"Dependency loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Udacity's data\n",
    "df = pd.read_csv('data/driving_log.csv', header=0)\n",
    "df.columns = [\"center_image\", \"left_image\", \"right_image\", \"steering_angle\", \"throttle\", \"break\", \"speed\"]\n",
    "\n",
    "# Load continued recovery data\n",
    "df_recovery = pd.read_csv('data/driving_log_recovery.csv', header=0)\n",
    "df_recovery.columns = [\"center_image\", \"left_image\", \"right_image\", \"steering_angle\", \"throttle\", \"break\", \"speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_right = []\n",
    "df_left = []\n",
    "df_center = []\n",
    "# NVIDIA's input parameters\n",
    "INPUT_IMG_HEIGHT = 66\n",
    "INPUT_IMG_WIDTH = 220\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the rule of processing data\n",
    "sample_angles = []\n",
    "def process_data(data_source):\n",
    "    for i in range(len(data_source)):\n",
    "        center_img = data_source[\"center_image\"][i]\n",
    "        left_img = data_source[\"left_image\"][i]\n",
    "        right_img = data_source[\"right_image\"][i]\n",
    "        angle = data_source[\"steering_angle\"][i]\n",
    "        sample_angles.append(angle)\n",
    "        # Declearing data collection rule\n",
    "        if (angle > 0.15):\n",
    "            df_right.append([center_img, left_img, right_img, angle])\n",
    "\n",
    "        if (angle < -0.15):\n",
    "            df_left.append([center_img, left_img, right_img, angle])\n",
    "\n",
    "        if (angle != 0):\n",
    "            df_center.append([center_img, left_img, right_img, angle])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed\n"
     ]
    }
   ],
   "source": [
    "# Process recovery's data\n",
    "process_data(df)\n",
    "\n",
    "# Process recovery's data\n",
    "process_data(df_recovery)\n",
    "\n",
    "print (\"Data processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106be8f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_sample_angles = np.asarray(sample_angles)\n",
    "a = plt.hist(np_sample_angles)\n",
    "plt.xlabel('Steering Angle')\n",
    "plt.ylabel('Samples')\n",
    "plt.title('The distribution of steering angles')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shuffled\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "random.shuffle(df_center)\n",
    "random.shuffle(df_left)\n",
    "random.shuffle(df_right)\n",
    "\n",
    "print (\"Data shuffled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_center = pd.DataFrame(df_center, columns=[\"center_image\", \"left_image\", \"right_image\", \"steering_angle\"])\n",
    "df_left = pd.DataFrame(df_left, columns=[\"center_image\", \"left_image\", \"right_image\", \"steering_angle\"])\n",
    "df_right = pd.DataFrame(df_right, columns=[\"center_image\", \"left_image\", \"right_image\", \"steering_angle\"])\n",
    "\n",
    "# Put the Left, Right & Center together\n",
    "data_list = [df_center, df_left, df_right]\n",
    "data_list_df = pd.concat(data_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center Sample:  1540\n",
      "Left Sample:  695\n",
      "Right Sample:  442\n"
     ]
    }
   ],
   "source": [
    "print(\"Center Sample: \",len(data_list[0]))\n",
    "print(\"Left Sample: \",len(data_list[1]))\n",
    "print(\"Right Sample: \",len(data_list[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X_train_data, X_valid_data, y_train_data, y_valid_data\n",
    "## Split into Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = data_list_df[[\"center_image\",\"left_image\",\"right_image\",\"steering_angle\"]]\n",
    "y_data = data_list_df[\"steering_angle\"]\n",
    "\n",
    "X_data = pd.DataFrame(X_data, columns=[\"center_image\", \"left_image\", \"right_image\", \"steering_angle\"])\n",
    "y_data = pd.DataFrame(y_data, columns=[\"steering_angle\"])\n",
    "\n",
    "X_train_data, X_valid_data, y_train_data, y_valid_data = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "# Reset Index on DataFrame\n",
    "X_train_data = X_train_data.reset_index(drop=True)\n",
    "X_valid_data = X_valid_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "### Change brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(image):\n",
    "    # Randomly select a percent change\n",
    "    change_pct = random.uniform(0.4, 1.2)\n",
    "\n",
    "    # Change to HSV to change the brightness V\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv[:,:,2] = hsv[:,:,2] * change_pct\n",
    "\n",
    "    #Convert back to RGB\n",
    "    img_bright = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return img_bright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flip Image\n",
    "def flip_image(image, angle):\n",
    "    img_flip = cv2.flip(image,1)\n",
    "    angle = -angle\n",
    "\n",
    "    return img_flip, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessImage(image):\n",
    "    # Proportionally get lower half portion of the image\n",
    "    nrow, ncol, nchannel = image.shape\n",
    "\n",
    "    start_row = int(nrow * 0.35)\n",
    "    end_row = int(nrow * 0.875)\n",
    "\n",
    "    ## This removes most of the sky and small amount below including the hood\n",
    "    image_no_sky = image[start_row:end_row, :]\n",
    "\n",
    "    # This resizes to 66 x 220 for NVIDIA's model\n",
    "    new_image = cv2.resize(image_no_sky, (220,66), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train(data_row_df):\n",
    "\n",
    "    path_filename = data_row_df[\"center_image\"][0]\n",
    "    image = cv2.imread(path_filename)\n",
    "    angle = data_row_df['steering_angle'][0]\n",
    "\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image = change_brightness(image)\n",
    "\n",
    "    # Coin flip to see to flip image and create a new sample of -angle\n",
    "    if np.random.randint(2) == 1:\n",
    "        image, angle = flip_image(image, angle)\n",
    "\n",
    "    # This preprocessImage() needs to be done in drive.py\n",
    "    image = preprocessImage(image)\n",
    "    image = np.array(image)\n",
    "\n",
    "    return image, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid(data_row_df):\n",
    "\n",
    "    path_filename = data_row_df[\"center_image\"][0]\n",
    "    angle = data_row_df['steering_angle'][0]\n",
    "    image = cv2.imread(path_filename)\n",
    "\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # This preprocessImage() needs to be done in drive.py\n",
    "    image = preprocessImage(image)\n",
    "    image = np.array(image)\n",
    "\n",
    "    return image, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch_train_from_dataframe(data_df, batch_size = 128):\n",
    "\n",
    "    batch_images = np.zeros((batch_size, INPUT_IMG_HEIGHT, INPUT_IMG_WIDTH, 3))\n",
    "    batch_angles = np.zeros(batch_size)\n",
    "\n",
    "    while True:\n",
    "        for i in range (batch_size):\n",
    "            # Randomly get a sample from the input data\n",
    "            idx = np.random.randint(len(data_df))\n",
    "\n",
    "            # reset_index sets this data_df starting row to 0\n",
    "            data_row = data_df.iloc[[idx]].reset_index()\n",
    "            img1, angle1 = preprocess_image_train(data_row)\n",
    "\n",
    "            batch_images[i] = img1\n",
    "            batch_angles[i] = angle1\n",
    "\n",
    "        yield batch_images, batch_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_valid_from_dataframe(data_df):\n",
    "    while True:\n",
    "        for idx in range(len(data_df)):\n",
    "            data_row = data_df.iloc[[idx]].reset_index()\n",
    "            img, angle = preprocess_image_valid(data_row)\n",
    "\n",
    "            # Since not stacking the images, it's shape remains (height, width, channel)\n",
    "            # but need it to be (1, height, width, channel)\n",
    "            img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "            angle = np.array([[angle]])\n",
    "            yield img, angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initiated\n"
     ]
    }
   ],
   "source": [
    "valid_data_generator = generate_valid_from_dataframe(X_valid_data)\n",
    "print(\"Generator initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape defined\n"
     ]
    }
   ],
   "source": [
    "input_shape = (INPUT_IMG_HEIGHT, INPUT_IMG_WIDTH, 3)\n",
    "print(\"Input shape defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_generator = generate_batch_train_from_dataframe(X_train_data, batch_size)\n",
    "val_size = len(X_valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model from NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nvidia_net():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,input_shape = input_shape))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal', name='conv1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal', name='conv2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal', name='conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init='he_normal', name='conv4'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init='he_normal', name='conv5'))\n",
    "    \n",
    "    model.add(Flatten(name='flatten1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1164, init='he_normal', name='dense1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, init='he_normal', name='dense2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, init='he_normal', name='dense3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, init='he_normal', name='dense4'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1, init='he_normal', name='dense5'))\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 220, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Convolution2D)            (None, 31, 108, 24)   1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 31, 108, 24)   0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 31, 108, 24)   0           elu_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Convolution2D)            (None, 14, 52, 36)    21636       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 14, 52, 36)    0           conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 14, 52, 36)    0           elu_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3 (Convolution2D)            (None, 5, 24, 48)     43248       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 5, 24, 48)     0           conv3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 5, 24, 48)     0           elu_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4 (Convolution2D)            (None, 3, 22, 64)     27712       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 3, 22, 64)     0           conv4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 3, 22, 64)     0           elu_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv5 (Convolution2D)            (None, 1, 20, 64)     36928       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten1 (Flatten)               (None, 1280)          0           conv5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_5 (ELU)                      (None, 1280)          0           flatten1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense1 (Dense)                   (None, 1164)          1491084     elu_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_6 (ELU)                      (None, 1164)          0           dense1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense2 (Dense)                   (None, 100)           116500      elu_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_7 (ELU)                      (None, 100)           0           dense2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense3 (Dense)                   (None, 50)            5050        elu_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_8 (ELU)                      (None, 50)            0           dense3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense4 (Dense)                   (None, 10)            510         elu_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_9 (ELU)                      (None, 10)            0           dense4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense5 (Dense)                   (None, 1)             11          elu_9[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 1,744,503\n",
      "Trainable params: 1,744,503\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_test = nvidia_net()\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size = len(X_valid_data)\n",
    "batch_size = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(fileModelJSON, fileWeights):\n",
    "    prefix = \"model/\"\n",
    "    \n",
    "    filenameJSON = prefix + fileModelJSON\n",
    "    if Path(filenameJSON).is_file():\n",
    "        os.remove(filenameJSON)    \n",
    "    with open (filenameJSON, 'w') as outfile:\n",
    "        json.dump(model.to_json(), outfile)\n",
    "        \n",
    "    filenameWeights = prefix + fileWeights\n",
    "    if Path(filenameWeights).is_file():\n",
    "        os.remove(filenameWeights)\n",
    "    model.save_weights(filenameWeights, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hang/anaconda/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/hang/anaconda/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/hang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-16-cceec8d0f6ea>\", line 13, in generate_batch_train_from_dataframe\n",
      "    img1, angle1 = preprocess_image_train(data_row)\n",
      "  File \"<ipython-input-14-8d3230ab3986>\", line 7, in preprocess_image_train\n",
      "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
      "cv2.error: /Users/jenkins/miniconda/1/x64/conda-bld/work/opencv-3.1.0/modules/imgproc/src/color.cpp:7341: error: (-215) scn == 3 || scn == 4 in function ipp_cvtColor\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5835ab83f489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit_generator(train_data_generator, samples_per_epoch=20480,\n\u001b[1;32m      4\u001b[0m                                  \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                  nb_val_samples=val_size)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfileModelJSON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hang/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/Users/hang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1530\u001b[0m                                          \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m                                          \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1533\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "train_data_generator = generate_batch_train_from_dataframe(X_train_data, batch_size)\n",
    "model = nvidia_net()\n",
    "history = model.fit_generator(train_data_generator, samples_per_epoch=20480,\n",
    "                                 nb_epoch=6, validation_data=valid_data_generator,\n",
    "                                 nb_val_samples=val_size)\n",
    "    \n",
    "fileModelJSON = 'model.json'\n",
    "fileWeights = 'model.h5'\n",
    "save_model(fileModelJSON, fileWeights)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('video.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
